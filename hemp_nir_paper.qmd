---
title: Near Infrared Spectroscopy Predicts Crude Protein Concentration in Hemp Grain
execute:
  freeze: auto
  echo: false

format:
  html:
    theme: default
    toc: true
    toc-depth: 3
    embed-resources: true
    fig-width: 8
    fig-height: 6
  docx:
    toc: true
    fig-width: 6.5
    fig-height: 4.5
    prefer-html: true
    reference-doc: reference.docx
  
author:
  - name: Ryan V. Crawford
    orcid: 0009-0006-3052-3269
    corresponding: true
    email: rvc3@cornell.edu
    affiliations:
      - name: Cornell University
        address: 126 Medicago Drive
        city: Ithaca
        state: NY
        postal-code: 14853
  - name: Jamie L. Crawford
    orcid: 0009-0002-2523-3479
    corresponding: false
    affiliations:
      - name: Cornell University
        address: 126 Medicago Drive
        city: Ithaca
        state: NY
        postal-code: 14853
  - name: Julie L. Hansen
    orcid: 0000-0001-7247-9186
    corresponding: false
    affiliations:
      - name: Cornell University
        address: 126 Medicago Drive
        city: Ithaca
        state: NY
        postal-code: 14853
  - name: Lawrence B. Smart
    orcid: 0000-0002-7812-7736
    corresponding: false
    affiliations:
      - name: Cornell AgriTech
        address: 102 Hedrick Hall
        city: Geneva
        state: NY
        postal-code: 14456
  - name: Virginia M. Moore
    orcid: 0000-0001-7888-3366
    corresponding: false
    affiliations:
      - name: Cornell University
        address: 162 Emerson Hall
        city: Ithaca
        state: NY
        postal-code: 14853    
title-block-style: none
keywords:
  - Hemp
  - Grain
  - Spectroscopy
abstract: |
      The protein concentration of hemp (*Cannabis sativa* L.) grain is of interest to researchers, producers, and consumers. This study was conducted to determine whether hemp grain can be non-destructively assayed for crude protein (CP) concentration using spectra obtained from near-infrared spectroscopy (NIRS) to build a prediction model for CP using partial least squares regression (PLSR). One hundred and fourty-nine whole hemp grain samples were obtained from 18 cultivar trials in New York (NY) from 2017-2021. Their spectra were measured with a benchtop NIRS instrument, and then ground and assayed by combustion to directly measure CP concentration. Seven potential preprocessing methods, as well as untransformed spectra, were tested using 100 training and testing set splits of the data and the best method was selected. That method was applied to 1000 additional splits of the data set. Model fit was evaluated using RMSE, R^2^, relative predicted deviation (RPD), and ratio of performance to interquartile distance (RPIQ). Once a preprocessing method was selected, the optimal number of model components and prediction performance on the testing sets were examined. A preprocessing method consisting of the standard normal variate transformation following a Savitzky-Golay filter had the lowest RMSE and the highest R^2^, RPD and RPIQ, with RPD and RPIQ 2.1%, and 2.4% higher than a Savitzky-Golay filter by itself (significant at $\alpha$ \<0.05). All preprocessing methods outperformed untransformed spectra. Optimal final models typically consisted of 12 components. Seventy-four percent of the 1000 final models had, at minimum, the ability to distinguish between high and low values of CP concentration, with 49% of the models capable of approximating quantitative prediction. The models tended to overestimate CP concentration by 0.5% in the lowest tertile of samples and underestimate CP concentration by 0.4% in the highest tertile of samples. The worst-predicted samples tended to come from Geneva, NY, possibly as a result of the models' class imbalance (half of the samples were from Ithaca, NY while 28% were from Geneva). The research shows the promise that NIRS offers in the non-destructive assay of CP concentration in hemp grain.

plain-language-summary: |
  A model was developed to predict percent crude protein in hemp grain using near infrared spectroscopy.
key-points:
  - Models were developed to predict crude protein concentration in hemp grain using near infrared spectroscopy.
  - Most models were able to distinguish between high and lower concentrations of crude protein. 
  - Models could be further optimized by including more samples and rectifying class imbalances between environments.
date: last-modified
csl: apa.csl
number-sections: true
crossref:
  custom:
    - kind: float
      key: suppfig
      latex-env: suppfig
      reference-prefix: Figure S
      space-before-numbering: false
      latex-list-of-description: Supplementary Figure
bibliography: [references.bib, grateful-refs.bib]
---

```{r, message=FALSE, warning=FALSE}
#| label: setup
#| eval: true

library(knitr)
library(ggplot2)
library(targets)
library(nlme)
library(emmeans)

source("R/core_functions.R")


# Load all required targets objects
hemp_data <- tryCatch(tar_read(hemp_data), error = function(e) NULL)
best_method <- tryCatch(tar_read(best_method), error = function(e) "Not available")
final_model_analysis <- tryCatch(tar_read(final_model_analysis), error = function(e) NULL)
final_model_results <- tryCatch(tar_read(final_model_results), error = function(e) NULL)
hemp_data <- tryCatch(tar_read(hemp_data), error = function(e) NULL)

preprocessing_analysis <- tryCatch(tar_read(preprocessing_analysis), error = function(e) NULL)
preprocessing_comparison<- tryCatch(tar_read(preprocessing_comparison), error = function(e) NULL)
error_analysis<- tryCatch(tar_read(error_analysis), error = function(e) NULL)
protein_analysis<- tryCatch(tar_read(protein_analysis), error = function(e) NULL)
spectral_analysis <- tryCatch(tar_read(spectral_analysis), error = function(e) NULL)

table_model_comparison <- tar_read(vip_table)
# Also load the table and figure objects that are referenced later
table_sample_summary <- tryCatch(tar_read(table_sample_summary), error = function(e) NULL)
table_preprocessing <- tryCatch(tar_read(table_preprocessing), error = function(e) NULL)
fig_model_calibration <- tryCatch(tar_read(fig_calibration), error = function(e) NULL)
fig_performance_boxplot <- tryCatch(tar_read(fig_performance), error = function(e) NULL)
fig_validation_errors <- tryCatch(tar_read(fig_validation_errors), error = function(e) NULL)
fig_model_comparison <- tryCatch(tar_read(combined_vip_plot), error = function(e) NULL)

fig_algorithm_comparison <- tryCatch(tar_read(fig_algorithm_comparison), error = function(e) NULL)

table_performance_distribution<- tryCatch(tar_read(table_performance_distribution), error = function(e) NULL)
table_algorithm_comparison<- tryCatch(tar_read(table_algorithm_comparison), error = function(e) NULL)
table_performance_summary<- tryCatch(tar_read(table_performance_summary), error = function(e) NULL)



```

CP, crude protein; MAE,mean absolute error; NIR, near-infrared; NIRS, near-infrared spectroscopy; NY, New York; PLSR, partial least squares regression; RF, random forest; RPD, relative predicted deviation, RPIQ, ratio of performance to interquartile distance; SG, Savitzky-Golay; SNV, standard normal variate, SNV-SG, standard normal variate following Savitzky-Golay; SVM, support vector machines; VIP, variable importance in projection

## INTRODUCTION

Hemp (*Cannabis sativa* L.) is an annual crop with potential uses as a source of food or feed, derived from the grain, and fiber (bast or hurd), derived from the stalk. Hemp cultivars are commonly grown for one or both purposes, and a cultivar may be called a grain, fiber, or dual-purpose type [@tang_comparing_2016]. Because of its nutritional importance, the protein concentration of a grain crop is a prime consideration for researchers, producers, and consumers. Whole hemp grain typically contains approximately 200-300 g kg^−1^ crude protein (CP) [@ely_industrial_2022; @barta_proteomic_2024; @callaway_hempseed_2004; @liu_composition_2023]. Crude protein is a proxy for the direct measurement of protein concentration and consists of the multiplication of nitrogen concentration by a conversion factor, often 6.25 [@hayes_measuring_2020].

Near-infrared (NIR) spectroscopy (NIRS) technology is rapid, non-destructive, and inexpensive. It consists of the measurement of NIR radiation reflected and absorbed from a sample (the spectra). These spectra are then related to primary analytical values, typically obtained using wet chemistry assays, for components such as moisture, CP, fat, or fiber [@roberts_near-infrared_2004]. NIRS technology has been used since the 1970's to assess forage CP concentration [@reeves_potential_2012; @williams_application_1975]. A NIRS calibration set often consists of samples from diverse genotypes of one species grown in many environments encompassing the range of expected values from the analyte or analytes [@chadalavada_nir_2022].

Partial least squares regression (PLSR), a typical method used in the agricultural and food sciences, calculates components that maximize covariance between predictor and response variables to relate spectra to analyte [@roberts_near-infrared_2004]. It uses some number of components, often selected via cross-validation in order to avoid overfitting, to fit the regression model [@wold_pls-regression_2001]. It is commonly used in spectroscopy because it tends to work well with highly correlated, noisy spectral data . Variable importance in projection (VIP) scores show the amount response variable's variance explained by the predictor variables, with VIP scores of greater than one often serving as a criterion for variable selection [@farres_comparison_2015].

While PLSR is commonly used in agricultural applications, other algorithms may offer comparable or improved prediction accuracy. Support vector machines (SVM) and random forest (RF) algorithms have been utilized in NIRS applications, particularly where non-linear relationships exist between spectral features and analyte concentration [@chinilin_vis-nir_2023]. Support vector machines apply non-linear kernel functions to capture relationships between spectral data and analyte concentrations, with studies demonstrating competitive performance with PLSR for protein prediction in stored wheat grains @kamboj_comparison_2022. Random forest (RF) algorithms use ensemble learning to combine multiple decision trees and has been used to predict protein content in grains [@chadalavada_nir_2022; @haruna_intelligent_2022]. Comparing multiple algorithms helps ensure that the best approach is chosen.

The biological validity of NIRS predictions can be enhanced through targeted analysis of wavelength regions corresponding to known molecular absorption bands. Models developed using biologically-relevant wavelengths are evidence that predictions are based on CP-spectral relationships rather than spurious correlations with other quality components. Three spectral regions with established CP-related vibrational assignments are: 1200-1250 nm (C-H stretch 2nd overtone from amino acid side chains), 1500-1550 nm (N-H stretch 1st overtone from peptide bonds), 2040-2090 nm (N-H + C-N combination bands)[@kollmann_near-infrared_2023; @shi_estimation_2022]. Selecting spectral regions prior to model fitting avoids the bias that may result when data are used to simultaneously select a model and estimate parameters [@yates_cross_2023]. Models developed using portions of the NIRS spectra be more readily transferable between instruments because they discard noisy, irrelevant portions of the spectra [@wang_nirs-based_2025].

A NIRS-scanned sample of whole grain may be used for other purposes besides the scan, including planting as a seed or consumed, benefits attractive to plant breeders, farmers, and the food industry [@caporaso_near-infrared_2018]. In wheat and corn, grain CP content has been shown to be heritable [@giancaspro_genetic_2019; @geyer_genetics_2022]. This suggests that NIRS technology could serve as a resource to rapidly identify high concentration CP hemp germplasm, enabling the screening of germplasm as seed, before planting to the field, and facilitating the efficient development of high concentration CP hemp populations.

For this study, researchers hypothesized that a benchtop NIR spectrometer could be used to develop a model to accurately predict CP concentration based on a data set of hemp grain representing multiple years, locations, and cultivars from grain and dual-purpose hemp types using PLSR, RF, or SVM.

## MATERIALS AND METHODS

### Hemp Grain Sample Background

Spectral data were collected from whole (unground) hemp grain samples, harvested at maturity, collected from from `r nrow(distinct(hemp_data |> filter(loc!= "kentucky"), harv_year, loc))` experimental trials in New York (NY) between 2017 and 2021 (149 samples). Ninety percent of the samples were collected from Ithaca, Geneva, and Freeville NY. Grain samples were collected through hand sampling or mechanical harvest and were subsequently cleaned of chaff and dried at a temperature of 30 C for six days in a forced-air dryer. All CP values were expressed as concentration dry matter. In total, `r nrow(hemp_data)` samples from `r hemp_data$cultivar |> unique() |> length()` cultivars were represented in the data set. Cultivars were either grain or dual-purpose types and included both commercially available and experimental material. Seventy-eight samples were scanned and chemically assayed in 2017, 19 in 2018, 24 in 2019, and 28 in 2021. All cultivars and locations were represented in 2017, but only a selected subset of cultivar-location combinations were represented in 2018-2021 because not all cultivars were planted everywhere and only a portion of these cultivar-location combinations were sampled, scanned, and assayed due to logistical constraints. More information about hemp cultivars and locations is available in Supplemental Table S1.

```{r}
#| label: tbl-hemp-provenance
#| tbl-cap: "Sample distribution by location and type"

# OPTION 1: Read directly from source file (recommended)
library(data.table)
cultivar_data <- fread("input_data/final_data_set/cultivar_table_clean.csv")

# Create the table using knitr::kable for consistency with your style
cultivar_data |>
  knitr::kable(
    caption = "Tally of hemp cultivars and locations. Private cultivars are labeled 'Cultivar1', 'Cultivar2', etc., while experimental cultivars are labeled 'Experimental1', 'Experimental2', etc."
  )

```

All experimental trials were planted in randomized complete block design with each cultivar replicated four times. The 2017 data were comprised of samples from the same 13 cultivars sampled from six NY locations. For those trials, grain was harvested from each plot individually and aggregated by cultivar within each trial. Four subsamples were drawn from each aggregated sample and scanned separately. These 2017 spectra were averaged at each 2 nm increment. All remaining samples from 2018-2021 were collected on a per-plot basis.

### Spectral Data Collection and Preprocessing

A benchtop NIR spectrometer (FOSS/ NIR FOSS/ NIR Systems model 5000) was used to obtain the spectra (FOSS North America, Eden Prairie, MN, USA). Spectra were collected every 2 nm from 1100-2498 nm and the logarithm of reciprocal reflectance was recorded. A 1/4 rectangular sample cup (5.7 cm × 4.6 cm) was used to scan the samples.

WINISI software version 1.02A (Infrasoft International, Port Matilda, PA, USA) was used to calculate the mean spectra in 2017 and to select samples for laboratory assay in all years. Samples were selected according to their spectral distance from their nearest neighbor within the data set with a cutoff of a distance of 0.6 H, where H is approximately equal to the squared Mahalanobis distance divided by the number of principal components used in the calculation [@garrido-varo_note_2019]. The spectral cutoff threshold of 0.6 H is a metric used to optimize the number of samples for chemical analysis [@nogales-bueno_reduction_2021 @shenk_population_1991]. Prior to selection, spectra were preprocessed using Standard Normal Variate (SNV)-detrend with settings 1,4,4,1 for the derivative, gap, smooth, and smooth-two settings respectively. These settings are standard WINISI software parameters and were applied because hemp grain samples were subject to light scatter and noise due to particle size variation, with the first derivative applied to show component absorption [@barnes_standard_1989; @towett_applicability_2013].

### Laboratory Validation

Laboratory assays were performed by Dairy One Forage Laboratory (Ithaca, NY). For those assays, 1 mm ground samples were analyzed by combustion using a CN628 or CN928 Carbon/Nitrogen Determinator. Samples from 2017 were aggregated as described above, but the remaining samples were not aggregated.

### R software and packages used

### Model Development

For all models, training and testing sets were created by dividing samples by their laboratory CP concentration values into three equal parts (tertiles) to ensure that a representative range of values was present in both training and testing sets and so that the model could predict across the entire range of data. Within each tertile, 75% of the samples were randomly assigned to the training set and the remaining 25% were assigned to the testing set. For each training set, models were developed in R's caret package using PLSR, RF, and SVM models. Model performance was evaluated with caret's default 25 iterations of bootstrapping and minimized RMSE in selecting the number of components in the final model. unless otherwise indicated, for PSLR models, the number of components was optimized over a grid search from one to 20. For SVM models, cost and sigma parameters were optimized using a grid search over 10 values. For RF models, eight variables were considered at each split and the number of trees was set to 500. For all models, performance was summarized using RMSE, R², RPD, and RPIQ.

Initially a number of common spectral preprocessing methods were tested by creating 100 training and testing sets, as described above. Spectral data were transformed by each of the following methods: 1) first derivative; 2) Savitzky-Golay (SG) using the first derivative, third order polynomial, and a window of size five; 3) gap-segment derivative using the first derivative, a gap of 11, and a segment size of five; 4) SNV; 5) standard normal variate following Savitzky-Golay (SNV-SG) using the same SG parameters as above; 6) SNV-detrend with second order polynomial; and 7) multiplicative scatter correction. For comparison, models were also developed using untransformed spectra.

For each of these preprocessing methods, PLSR models were fit and predictions were made on the corresponding testing set. Since there were seven preprocessing methods as well as untransformed spectra, eight separate models were fit for each of the 100 sets. The relationship between the predicted and actual values of the test set were calculated via RMSE, R^2^, relative predicted deviation (RPD), and ratio of performance to interquartile distance (RPIQ), four common model assessment metrics. Larger R^2^, RPD and RPIQ values and smaller RMSE values are best. There is a long history of using RPD to evaluate chemometric models although the statistic has been criticized as inadequately reflecting the distribution of skewed populations, a situation which RPIQ was designed to address [@bellon-maurel_critical_2010]. The answer to the question of exactly which values constitute a "good" model varies depending upon the reference consulted, but a simple rubric for model quality following @chadalavada_nir_2022 is set forth in [@tbl-model-rubric; @chadalavada_nir_2022; @luce_prediction_2017; @rawal_visible_2024]. There are more conservative definitions of model quality for which these categories would not suffice. For example, @williams_comparison_1993 suggests a minimal RPD of 2.5 for screening in breeding programs with values of 5-10 for quality control [@williams_calibration_2013].

```{r}
#| label: tbl-model-rubric
#| tbl-cap: "Model assessment rubric"

eval_criteria <- data.frame(
  Category = c("Excellent", "Good", "Fair", "Poor"),
  RPD = c("> 3.0", "2.0 - 3.0", "1.5 - 2.0", "< 1.5"),
  Interpretation = c(
    "Excellent quantitative prediction",
    "Good quantitative prediction",
    "Moderate prediction (quantitative)",
    "Poor prediction"
  )
)

kable(eval_criteria, 
      col.names = c("Category", "RPD", "Interpretation"),
      caption = "Model Evaluation Criteria for NIRS Prediction Models")
```

Analyses of variance were performed for each of these metrics in order to compare preprocessing methods. For ANOVAs involving preprocessing methods, each data set was considered as a subject and different variances were allowed for each preprocessing method .Post hoc comparisons were performed with Tukey method to compare estimates set to $\alpha$ = 0.05. Once the most promising preprocessing method was identified, it was used in all subsequent analyses.

To select an algorithm to fit a final model for these data, researchers compared three machine learning algorithms: PLSR, SVM (with radial basis function kernel), and random forest (RF). This comparison was conducted to validate the choice of PLSR through empirical evaluation against alternative algorithms and to assess whether more complex modeling approaches might improve predictive accuracy. One hundred random splits into training sets and testing sets were performed and models were constructed using each of the three algorithms. Statistical significance of performance differences between algorithms was assessed using analysis of variance.

Using the optimal preprocessing method identified above, one thousand training and testing sets were generated and models were developed. The larger number of iterations was feasible once the preprocessing method was selected, allowing for more robust performance estimates. The pattern of errors, expressed as the difference between the actual and predicted values for a given sample, was examined.

To validate the biological basis of spectroscopic predictions and ensure that models were responding to protein-related spectral features rather than chance correlations, a protein-focused model was developed using the same PLSR methodology as the full-spectrum model but restricted to three protein-relevant bands and a maximum of 15 components. Performance was compared to the full-spectrum model to assess whether targeted wavelength selection could maintain prediction accuracy while providing greater biological interpretability.

## RESULTS AND DISCUSSION

### Laboratory assay CP values

Laboratory assay CP concentration values are summarized in @tbl-protein-summary. These are similar to the range of values observed in the literature, indicating an reasonable basis for a chemometric model. The values were left-skewed (skewness of `r round(calculate_skewness(hemp_data$crude_protein), 2)`) and two thirds of the samples contained more than 250 g kg ^-1^ CP.

```{r}
#| label: tbl-protein-summary
#| tbl-cap: "Summary of laboratory-assayed CP values"

table_sample_summary
```

### Preprocessing methods comparison

Among the eight methods compared via ANOVA, the SNV-SG and SG preprocessing methods performed the best and were in the best highest-performing post-hoc comparison group. The SNV-SG method had the lowest RMSE and the highest R^2^, RPD and RPIQ averaging over all iterations (@tbl-preproc). The superiority of SNV-SG by these metrics made it the best choice for the final model.

```{r, message=FALSE, warning=FALSE}


method_comparison_marginal_means <- preprocessing_comparison |> 
  mutate(across(c(preprocessing_method, iteration), as.factor)) |> 
  pivot_longer(-c(1:3)) |> 
  nest(-name) |> 
  mutate(model = map(data, ~lme(value~preprocessing_method, random = ~1|iteration,
          weights = varIdent(form = ~ 1 | preprocessing_method), data = .x)),
         marginal_means = map(model, ~emmeans(.x, "preprocessing_method") |> multcomp::cld() |> 
                                as.data.frame()))
```

```{r}
#| label: tbl-preproc
#| tbl-cap: Evaluation of Preprocessing Methods by Metric ± Standard Error

table_preprocessing
```

From the literature, these results are readily explained. Standard normal variate and SNV-detrend both correct light scatter, which is often a function of differences in particle size and sample packing density, although SNV-detrend is often used for densely-packed, powdered samples [@barnes_standard_1989]. SG is a smoothing filter that regresses on the signal over a series of windows, removing noise while preserving the signal's shape and features [@li_quantitative_2020; @luo_properties_2005]. Derivatives, here including SG, gap-segment, and first derivatives pretreatments may remove additive and multiplicative effects, but not necessarily light scatter; as well, derivatives may increase spectral noise [@rinnan_review_2009]. Here, hemp grain was neither powdered nor densely packed but samples were subject to light scatter and noise due to differences in particle size in the hemp grain.

### Algorithm comparison

The algorithm comparison revealed clear performance differences among the three approaches, with PLSR achieving significantly superior performance across all evaluation metrics (@tbl-algorithm-comparison). This suggests that the spectral features captured by PLSR are well-suited for hemp grain protein prediction, at least for screening, while the additional complexity of non-linear algorithms did not provide predictive advantage. This contrasts with researchers who obtained their best predictions of grains or seeds using machine learning methods other than PLSR (SVM and convolutional neural networks,respectively) , although in the present case the training sets were less than half the size of those used by the other researchers [@huang_feasibility_2013; @chadalavada_nir_2022].

```{r}
#| label: tbl-algorithm-comparison
#| fig-cap: Comparing algorithms

table_algorithm_comparison
```

The superior performance of PLSR in this relatively small data set validates its selection as the primary modeling algorithm. Statistical analysis confirmed significant differences between algorithms across all four performance metrics (p \< 0.05), indicating robust performance differences despite the relatively modest sample size.

### PLSR full spectrum model development

```{r, message=FALSE, warning=FALSE, results = 'hide'}
# check results
final_results <- final_model_results$model_n_comp_statistics
final_summary <- final_results[,list(mean_RMSE = mean(RMSE)), by = ncomp]

final_summary[, pct_change :=(mean_RMSE/shift(mean_RMSE)-1)*100]

# check components 1-7

range(final_summary$pct_change[1:7], na.rm = T)
# components 8-12
range(final_summary$pct_change[8:12], na.rm = T)
```

The model improved most rapidly as the number of components increased from one to seven, with the inclusion of each additional component being associated with a decrease in RMSE of 6%-11%. From eight to 12 components, model performance continued to improve, although gains were more modest. With 13 or more components, performance gains were minimal and the relative ranks of the models tended to be stable (@fig-model-calibration). The visible plateau in the plot at 12 components showed the point where the inclusion of additional components failed to improve model performance on the cross validation holdout set and indicated that the model was optimized and not overfit.

```{r}
#| label: fig-model-calibration
#| fig-cap: Decreasing RMSE with increasing number of components for 1000 training sets

fig_model_calibration
```

The performance of the final models on the testing sets is summarized in @fig-performance-boxplot. The means of the final models were: RMSE = `r round(mean(final_model_analysis$metrics$rmse), 2)`, R^2^ = `r round(mean(final_model_analysis$metrics$rsq), 2)`, RPD = `r round(mean(final_model_analysis$metrics$rpd), 2)`, and RPIQ = `r round(mean(final_model_analysis$metrics$rpiq), 2)`. Nearly of the models had, at minimum, the ability to distinguish between high and low values with `r final_model_analysis$quantitative_capable`% having some capacity for quantitative prediction. Despite generally reasonable model performance, a subset of poor models can be seen in the boxplots.

```{r}
#| label: fig-performance-boxplot
#| fig-cap: Final model testing set performance over 1000 iterations

fig_performance_boxplot
```

This is a more lax standard for RPD than that set forth by @williams_calibration_2013, who recommended a minimum acceptable RPD value of 2.5 as suitable rough screening, such as in plant breeding programs. Utilizing those higher benchmarks, `r round(final_model_analysis$metrics[rpd>2.4] |> nrow()/10)`% of the models were sufficient for rough screening and `r round(final_model_analysis$metrics[rpd>3.1] |> nrow()/10)`% were suitable for screening, although none sufficed for quality or process control. However, models with lower RPD values can still be of use to researchers [@bellon-maurel_critical_2010].

The pattern of test set errors was examined on a per-sample basis by calculating the difference between the actual and predicted values for the samples in the test sets (@fig-validation-errors). The models showed systematic bias, with overestimation in the lowest tertile and underestimation in the highest tertile samples. It is known that PLSR predictions are biased towards the mean values in the training set [@bellon-maurel_critical_2010]. The behavior of these predictions follows that pattern. The variance of the errors did not increase appreciably as CP concentration increased.

```{r}
#| label: fig-validation-errors
#| fig-cap: Testing set prediction errors on a per-sample basis. Actual sample value set to zero and samples ranked from least to greatest actual CP concentration value 

fig_validation_errors
```

```{r, message=FALSE, warning=FALSE, results = 'hide'}
# check errors
location_key <- fread("./input_data/final_data_set/location_key.txt")

samples_with_errors <- error_analysis$sample_errors |> 
  select(1:4) |> 
  left_join(hemp_data |> select(ith_in_data_set, loc, year)) |> left_join(location_key) |> 
  mutate(absolute_error = abs(mean_error)) |> 
  arrange(absolute_error)

abs_error_by_location <- samples_with_errors[,list(MAE = mean(absolute_error)), by = loc2]

mae_gen_vs_ithaca <- (10.9-6.7)/6.7
mae_gen_vs_free <- (10.9-4.3)/4.3

abs_error_by_years <- samples_with_errors[,list(MAE = mean(absolute_error)), by = year]
 samples_with_errors[,.N, by = year]

 (11.5-6.3)/6.3

 
```

The 15 (10%) best and 15 worst predicted samples as measured by the mean absolute error of prediction were identified and their backgrounds examined. Overall, half of the samples in the data set came from Ithaca, while 28% were collected from Geneva, NY. However, of the 15 worst-predicted samples, ten were from Geneva, while four of the 15 best-predicted samples were from Geneva (by contrast, five of the best-predicted and five of the worst-predicted samples came from Ithaca). Overall, samples from Geneva had the highest mean absolute error (MAE) of prediction among locations, 63% greater than samples from Ithaca and 153% greater than samples from Freeville, NY (the only locations where more than 20 samples were assayed).

Trials in Geneva and Ithaca were generally planted and harvested near the same date, and samples were assayed with the NIRS instrument within the same few weeks between field seasons. The likeliest explanation is variation in sample-handling, particularly harvesting and grain-cleaning, or variation in environmental condititions across growing seasons. However, the exact reason for these differences is likely unknowable.

### Protein-Focused Model Validation

```{r, message=FALSE, warning=FALSE, results = 'hide'}

pr <- protein_analysis$metrics |> mutate(analysis = "protein")
sp <- spectral_analysis$metrics |> mutate(analysis = "full")

model_comparison_marginal_means <- bind_rows(pr, sp) |> 
  mutate(across(c(iteration), as.factor)) |> 
  pivot_longer(c(rmse:rpiq)) |> 
  nest(-name) |> 
  mutate(model = map(data, ~lm(value~analysis + iteration, data = .x)),
         marginal_means = map(model, ~emmeans(.x, "analysis") |> multcomp::cld() |> 
                                as.data.frame()))

# look at spectral VIPs

spec_vips <- spectral_analysis$vip_scores

spec_vips[important==TRUE]

```

The biological basis of the NIRS predictions was validated by developing a protein-focused model using wavelengths within known protein absorption bands. That model was compared to full-spectrum model performance in @tbl-performance-summary. The protein-focused model utilized five components, aligning with the advice to use 20 samples for calibration per principal component in PLSR [@williams_calibration_2013]. By that rubric, a model using five principal components would require at least 100 samples to calibrate it. Here 111 samples were used in calibration, exceeding that threshold. However, the full spectrum model significantly outperformed the full-spectrum model across all performance metrics.Eighty-six percent of the protein-focused models were minimally acceptable for qualitative screening (RPD \> 1.5) but only 14% of the models were capable of approximate-quantitative screening or better.

```{r, message=FALSE, warning=FALSE, results = 'hide'}
#| label: tbl-performance_distribution
#| tbl-cap: "Enhanced performance comparison demonstrating biological validation through protein-specific wavelength selection"

table_performance_distribution
```

```{r}
#| label: tbl-performance-summary
#| tbl-cap: "Comparison of Protein-Focused and Full Spectrum Models"

table_performance_summary
```

Variable Importance in Projection (VIP) scores revealed that the protein-focused model concentrated predictive power in the expected molecular absorption regions (@fig-model-comparison). The 1500-1550 nm region (N-H stretch from peptide bonds) showed the highest importance, followed by the 1200-1250 nm region (N-H + C-N combination bands). VIP scores greater than one appeared in all 1000 model iterations at the 1246, 1248, 1546, and 1548 nm wavelengths. This pattern aligns with established protein spectroscopy literature [@lukacs_comparison_2024; @lorenz-fonfria_infrared_2020]. Thirty-one full spectrum models contained a VIP score of greater than one. These scores were concentrated in the range between 1876 and 1908 nm a region associated with protein absorption [@wu_determination_2023]. The VIP scores from either model could be used in subsequent model development [@wang_portable_2022].

```{r,  message=FALSE, warning=FALSE, results = 'hide'}
#| label: tbl_mod_compare

table_model_comparison
```

```{r}
#| label: fig-model-comparison
#| fig-cap: Comparing models developed using full and protein-specific spectra

fig_model_comparison
```

Despite its poorer performance, the protein-focused model provided biological validation of NIRS predictions as shown by the high VIP scores around 1250 and 1550 nm. This approach improved model interpretability by explicitly connecting predictions to known CP chemistry. That could improve model robustness and transferability across NIR instruments or environments, potentially enabling the transfer of calibrations to handheld or other instruments [@chadalavada_nir_2022; @lukacs_comparison_2024]. It is evidence that successful predictions are based on genuine CP-spectral relationships rather than correlations with other grain components such as oil, starch, or moisture.

## Conclusions

The research showed the promise of the use of NIRS in order to make predictions, at minimum, suitable for use in a breeding program, concerning CP concentration in hemp grain using PLSR. Promising preprocessing methods were identified and a model was validated. Further research could refine the model by including more samples or exploring using other mechanisms for variable selection. In the present case it would likely be particularly useful to rectify the class imbalance between Geneva and Ithaca.

This study is limited in that it represents the creation of one model based upon spectra collected from one machine. This is insufficient for use in an industrial setting, where a minimum of three machines are suggested and the prediction achieved here is lower than those needed for many industries [@williams_calibration_2013]. NIRS calibrations can be unique to a particular machine, even if the machines compared are of the same model [@reeves_potential_2012]. As well, the testing and training sets are relatively small.

However, these predictions may be sufficient for screening by a breeding program. If so, the biological validation of spectroscopic predictions opens new possibilities for accelerating hemp protein improvement through plant breeding. The non-destructive nature of NIRS allows breeders to analyze individual seeds while preserving their viability for planting, enabling selection decisions based on protein content before committing land and resources to field evaluation. For genomic selection programs, the ability to phenotype large populations (thousands of individuals) cost-effectively using NIRS could substantially improve the accuracy of genomic selection for protein content, accelerating genetic gains compared to traditional phenotyping approaches.

## ACKNOWLEDGMENTS

This work would not have been possible without the efforts of the field staff, undergraduate, and graduate students who planted, maintained, monitored and harvested these trials. Funding was provided by New York State through a grant from Empire State Development (AC477). We are grateful to those who provided seed for this project, including: Uniseeds, Verve Seeds, Winterfox Farms, International Hemp, Fiacre Seeds, and KonopiUS.

## CONFLICT OF INTEREST

The authors declare no conflict of interest.

**Generated:** `r format(Sys.time())`\
**Framework:** Targets-based reproducible workflow
